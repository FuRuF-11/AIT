# 应用于机器学习的算法信息论

作为最初的10位参加达特茅斯会议的先贤，所罗门诺夫发明算法概率的初衷，就是希望能从归纳法的角度取实现AI。也正是因此，我们可以看到AIT在AI领域有诸多的直接应用，尤其是在机器学习（Machine Learning）中。

## 从压缩的视角看机器学习

学习（learning）是一个动词，这注定我们可以有无数种方法和视角来看待机器学习这个领域。这种特性使得机器学习理论变成了一个多样到有些繁杂的领域。但是实际上，在压缩的视角下，机器学习这件事情就如同阳光下的一片叶子一样有着的清晰的脉络和主干。因为从算法信息论的角度来看，学习这件事情本质上就是压缩。


## 最短描述长度

AIT在机器学习中的最广为人知的理论贡献是最短描述长度。


## 神经网络与所罗门诺夫归纳法

神经网络的泛化能力来源于其内部对于柯氏复杂度较低的函数的偏好。


## 神经网络中的柏拉图假说

在机器学习的研究领域中，有学者类比柏拉图的洞穴寓言提出了[柏拉图假说](https://phillipi.github.io/prh/)（Platonic Hypothesis）。

这个假说认为：**在不同数据和模式上以不同目标进行训练的神经网络正在其表示空间中收敛为现实的共享统计模型。**
