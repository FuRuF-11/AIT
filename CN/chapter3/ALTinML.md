# 应用于机器学习的算法信息论

作为最初的10位参加达特茅斯会议的先贤，所罗门诺夫发明算法概率的初衷，就是希望能从归纳法的角度取实现AI。也正是因此，我们可以看到AIT在AI领域有诸多的直接应用，尤其是在机器学习（Machine Learning）中。

## 从压缩的视角看机器学习

学习（learning）是一个抽象的动词，这注定我们可以有无数种方法和视角来看待机器学习这个领域。这种特性使得机器学习理论变成了一个多样到有些繁杂的领域。但是实际上，在压缩的视角下，机器学习这件事情就如同阳光下的一片叶子一样有着的清晰的主干和脉络。因为从算法信息论的角度来看，学习这件事情本质上就是在压缩数据。


## 最短描述长度

AIT在机器学习中的最广为人知的理论贡献是最短描述长度。


## 神经网络与所罗门诺夫归纳法

神经网络的泛化能力来源于其内部对于柯氏复杂度较低的函数的偏好。


## 柏拉图假说


<!-- ## 柏拉图的洞穴寓言

在柏拉图的洞穴寓言中，一些可怜的囚犯从出生开始就锁在一个漆黑的洞穴中。他们所有人都被锁在一面石壁前，不能转头，只能看着墙壁。这个洞穴中还有一群守卫，他们在这些囚犯身后点起了一堆火，囚犯之间是一条高高的带有矮墙的人行道，守卫则在手里拿着“人和其他生物”的物品或木偶在道上行走。

对于这些被锁住的可怜囚犯来说，那些墙上的阴影就是他们的整个世界。他们对于整个世界的认知都来源于这些影子。

作为生活在现代的自由人，你也许很难想象这些囚犯是如何认知整个世界的。但是实际上从某种意义上来讲，我们也是一群被锁在石壁前的囚犯。

实际上，当我们观察到某件事情发生时，我们实际上也是在通过火炬在墙上的投影来观察这个世界。这些投影对于那些囚犯来说是墙上的影子，对我们来说则是我们听到的声音、看到的光线和触碰时的压感等等。

可以说对于发生在现实世界中的事件，我们仅仅只是通过我们的神经器官观察到了其部分结果，而这些事件背后发生的具体原因对于我们其实有相当一部分是未知的。

我们能否直接的通过感官来认识到这个世界背后的运行规律？我想这是极为困难的。对于我们来说，万事万物的背后都有无穷的可能性，而我们有限的感官无法接受所有的信息，也无法对所有的可能性进行判断。

但是有一点我们可以确信，那就是一件事只要发生就必然有导致它发生的唯一原因。正如洞穴中不同的囚犯从不同角度看到相同物体的不同影子。

也正是为了处理这种万事万物的背后的不确定性，概率论诞生了。我们将所有这些事件组成了一个事件空间，并根据据此赋予了每个事件一个概率。在大数定律的规约下，我们可以确信，这些事件的发生的概率最终会符合某种分布的描述。

而算法概率与传统概率的不同就从这里开始。 -->


在机器学习的研究领域中，有学者类比柏拉图的洞穴寓言提出了[柏拉图假说](https://phillipi.github.io/prh/)（Platonic Hypothesis）。

这个假说认为：**在不同数据和模式上以不同目标进行训练的神经网络正在其表示空间中收敛为现实的共享统计模型。**
